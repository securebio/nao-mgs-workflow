// Currently universal settings
docker.enabled = true
wave.enabled = true
aws.client.maxConnections = 1000
aws.client.maxErrorRetry = 10
aws.client.connectionTimeout = 0
aws.client.socketTimeout = 0
nextflow.enable.moduleBinaries = true

params {
    db_download_timeout = 1200 // Timeout in seconds for database downloads (default: 20 minutes)
}

// Workflow run profiles
profiles {
    standard { // Run on AWS Batch
        fusion.enabled = true
        fusion.exportStorageCredentials = true
        process.executor = "awsbatch"
        process.errorStrategy = "retry"
        process.maxRetries = 3
        aws.batch.volumes = ['/scratch:/scratch'] // Shared directory for large reference files
    }
    batch { // Run on AWS Batch
        fusion.enabled = true
        fusion.exportStorageCredentials = true
        process.executor = "awsbatch"
        process.errorStrategy = "retry"
        process.maxRetries = 3
        aws.batch.volumes = ['/scratch:/scratch'] // Shared directory for large reference files
    }
    ec2_local { // Run on EC2 instance with a local working directory
        wave.enabled = false
        fusion.enabled = false
        process.errorStrategy = "finish"
        docker.runOptions = '-v /home/ec2-user/.aws:/root/.aws -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY'
        // Mount AWS credentials to the container; required for S3 access
    }
    ec2_s3 { // Run on EC2 instance with an S3 working directory
        fusion.enabled = true
        fusion.exportStorageCredentials = true
        process.errorStrategy = "retry"
    }
}

// Set working directory
workDir = "${params.base_dir}/work"
