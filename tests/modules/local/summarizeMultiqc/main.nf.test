// Helper function: Validate TSV structure by reading lines directly and splitting by tabs.
// This approach works even when files have only headers (no data rows),
// which can cause issues with nf-test's CSV parser.
def validateTsvStructure = { tsv_file, expected_col_count, expected_stage, expected_sample ->
    def lines = path(tsv_file).linesGzip

    // Verify header exists and has correct number of columns
    assert lines.size() >= 1 : "TSV file must have at least a header row"
    def header = lines[0].split("\t")
    assert header.size() == expected_col_count : "Expected ${expected_col_count} columns, got ${header.size()}"

    // If there are data rows, verify stage and sample columns
    if (lines.size() > 1) {
        def first_data_row = lines[1].split("\t", -1) // -1 keeps trailing empty strings
        def stage_idx = header.findIndexOf { it == "stage" }
        def sample_idx = header.findIndexOf { it == "sample" }

        assert stage_idx >= 0 : "Header must contain 'stage' column"
        assert sample_idx >= 0 : "Header must contain 'sample' column"
        assert first_data_row[stage_idx] == expected_stage : "Expected stage '${expected_stage}', got '${first_data_row[stage_idx]}'"
        assert first_data_row[sample_idx] == expected_sample : "Expected sample '${expected_sample}', got '${first_data_row[sample_idx]}'"
    }
}

nextflow_process {

    name "Test process SUMMARIZE_MULTIQC"
    script "modules/local/summarizeMultiqc/main.nf"
    process "SUMMARIZE_MULTIQC"
    tag "module"
    tag "summarize_multiqc"

    test("Should handle empty input files properly") {
        tag "empty_input"
        tag "expect_success"
        config "tests/configs/run.config"
        setup {
            run("GZIP_FILE") {
                script "modules/local/gzipFile/main.nf"
                process {
                    """
                    input[0] = Channel.of("empty_sample").combine(Channel.of("${projectDir}/test-data/toy-data/empty_file.txt"))
                    """
                }
            }
            run("FASTQC_LABELED") {
                script "modules/local/fastqc/main.nf"
                process {
                    """
                    input[0] = GZIP_FILE.out
                    """
                }
            }
            run("MULTIQC_LABELED") {
                script "modules/local/multiqc/main.nf"
                process {
                    """
                    input[0] = "test"
                    input[1] = FASTQC_LABELED.out.zip
                    """
                }
            }
        }
        when {
            params {}
            process {
                """
                input[0] = MULTIQC_LABELED.out.data
                input[1] = true
                """
            }
        }
        then {
            // Should run without failures
            assert process.success
            // Output should preserve sample ID in tuple (sample is at index 0, files start at index 1)
            assert process.out[0][0][0] == "empty_sample"
            // Basic stats TSV should have expected structure and content
            def tsv_basic  = path(process.out[0][0][1]).csv(sep: "\t", decompress: true)
            with (tsv_basic) {
                assert rowCount == 1
                assert columnCount == 18
                def zero_cols = ["percent_gc", "mean_seq_len", "n_reads_single", "percent_duplicates", "n_bases_approx"]
                for (col in zero_cols) {
                    assert columns[col][0] == 0
                }
                assert columns["n_read_pairs"][0] == ""
                assert columns["per_base_sequence_quality"][0] == ""
                assert columns["per_tile_sequence_quality"][0] == ""
                assert columns["per_sequence_quality_scores"][0] == ""
                assert columns["stage"][0] == "test"
                assert columns["sample"][0] == "empty_sample"
            }
            def stage = tsv_basic.columns["stage"][0]
            def sample = tsv_basic.columns["sample"][0]
            // Length TSV should have expected structure and content (index 5)
            def tsv_lengths = path(process.out[0][0][5]).csv(sep: "\t", decompress: true)
            with (tsv_lengths) {
                assert columnCount == 5
                assert columns["stage"][0] == stage
                assert columns["sample"][0] == sample
                assert columns["n_sequences"][0] == 0
                assert columns["length"][0] == 0
            }
            // Other TSVs should have headers but no content
            def tsv_adapt = path(process.out[0][0][2]).linesGzip
            def tsv_adapt_headers = tsv_adapt[0].split("\t")
            assert tsv_adapt.size() == 1
            assert tsv_adapt_headers.size() == 6
            def tsv_qbase = path(process.out[0][0][3]).linesGzip
            def tsv_qbase_headers = tsv_qbase[0].split("\t")
            assert tsv_qbase.size() == 1
            assert tsv_qbase_headers.size() == 5
            def tsv_qseqs = path(process.out[0][0][4]).linesGzip
            def tsv_qseqs_headers = tsv_qseqs[0].split("\t")
            assert tsv_qseqs.size() == 1
            assert tsv_qseqs_headers.size() == 5
        }
    }

    test("Should run without failures on paired (non-interleaved) data") {
        tag "paired_end"
        tag "expect_success"
        config "tests/configs/run.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    '''
                    input[0] = "${projectDir}/test-data/samplesheet.csv"
                    input[1] = "illumina"
                    input[2] = false
                    '''
                }
            }
            run("FASTQC_LABELED") {
                script "modules/local/fastqc/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    '''
                }
            }
            run("MULTIQC_LABELED") {
                script "modules/local/multiqc/main.nf"
                process {
                    '''
                    input[0] = "test"
                    input[1] = FASTQC_LABELED.out.zip
                    '''
                }
            }
        }
        when {
            params {}
            process {
                """
                input[0] = MULTIQC_LABELED.out.data
                input[1] = false
                """
            }
        }
        then {
            // Should run without failures
            assert process.success
            // Output should preserve sample ID in tuple
            assert process.out[0][0][0] == "tiny_test"
            // Basic stats TSV should have expected structure and content (index 1)
            def tsv_basic  = path(process.out[0][0][1]).csv(sep: "\t", decompress: true)
            with (tsv_basic) {
                assert rowCount == 1
                assert columnCount == 18
                assert columns["n_reads_single"][0] == columns["n_read_pairs"][0] * 2
                assert columns["stage"][0] == "test"
            }
            def stage = tsv_basic.columns["stage"][0]
            def sample = tsv_basic.columns["sample"][0]
            // Other TSVs should have expected structure and content
            def tsv_adapt = process.out[0][0][2]
            validateTsvStructure(tsv_adapt, 6, stage, sample)
            def tsv_qbase = process.out[0][0][3]
            validateTsvStructure(tsv_qbase, 5, stage, sample)
            def tsv_qseqs = process.out[0][0][4]
            validateTsvStructure(tsv_qseqs, 5, stage, sample)
            def tsv_lengths = process.out[0][0][5]
            validateTsvStructure(tsv_lengths, 5, stage, sample)
        }
    }

    test("Should run without failures on paired (interleaved) data") {
        tag "expect_success"
        tag "interleaved"
        config "tests/configs/run.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    '''
                    input[0] = "${projectDir}/test-data/samplesheet.csv"
                    input[1] = "illumina"
                    input[2] = false
                    '''
                }
            }
            run("INTERLEAVE_FASTQ") {
                script "modules/local/interleaveFastq/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    '''
                }
            }
            run("FASTQC_LABELED") {
                script "modules/local/fastqc/main.nf"
                process {
                    '''
                    input[0] = INTERLEAVE_FASTQ.out.output
                    '''
                }
            }
            run("MULTIQC_LABELED") {
                script "modules/local/multiqc/main.nf"
                process {
                    '''
                    input[0] = "test"
                    input[1] = FASTQC_LABELED.out.zip
                    '''
                }
            }
        }
        when {
            params {}
            process {
                """
                input[0] = MULTIQC_LABELED.out.data
                input[1] = false
                """
            }
        }
        then {
            // Should run without failures
            assert process.success
            // Output should preserve sample ID in tuple
            assert process.out[0][0][0] == "tiny_test"
            // Basic stats TSV should have expected structure and content (index 1)
            def tsv_basic  = path(process.out[0][0][1]).csv(sep: "\t", decompress: true)
            with (tsv_basic) {
                assert rowCount == 1
                assert columnCount == 18
                assert columns["n_reads_single"][0] == columns["n_read_pairs"][0] * 2
                def n_bases_exp = Math.floor(columns["n_reads_single"][0] * columns["mean_seq_len"][0] / 100) * 100
                assert columns["n_bases_approx"][0] == n_bases_exp
                assert columns["stage"][0] == "test"
            }
            def stage = tsv_basic.columns["stage"][0]
            def sample = tsv_basic.columns["sample"][0]
            // Other TSVs should have expected structure and content
            def tsv_adapt = process.out[0][0][2]
            validateTsvStructure(tsv_adapt, 6, stage, sample)
            def tsv_qbase = process.out[0][0][3]
            validateTsvStructure(tsv_qbase, 5, stage, sample)
            def tsv_qseqs = process.out[0][0][4]
            validateTsvStructure(tsv_qseqs, 5, stage, sample)
            def tsv_lengths = process.out[0][0][5]
            validateTsvStructure(tsv_lengths, 5, stage, sample)
        }
    }

    test("Should run without failures on single-end data") {
        tag "expect_success"
        tag "single_end"
        config "tests/configs/run.config"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                process {
                    '''
                    input[0] = "${projectDir}/test-data/single-end-samplesheet.csv"
                    input[1] = "illumina"
                    input[2] = true
                    '''
                }
            }
            run("FASTQC_LABELED") {
                script "modules/local/fastqc/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    '''
                }
            }
            run("MULTIQC_LABELED") {
                script "modules/local/multiqc/main.nf"
                process {
                    '''
                    input[0] = "test"
                    input[1] = FASTQC_LABELED.out.zip
                    '''
                }
            }
        }
        when {
            params {}
            process {
                """
                input[0] = MULTIQC_LABELED.out.data
                input[1] = true
                """
            }
        }
        then {
            // Should run without failures
            assert process.success
            // Output should preserve sample ID in tuple
            assert process.out[0][0][0] == "tiny_test"
            // Basic stats TSV should have expected structure and content (index 1)
            def tsv_basic  = path(process.out[0][0][1]).csv(sep: "\t", decompress: true)
            with (tsv_basic) {
                assert rowCount == 1
                assert columnCount == 18
                def n_bases_exp = Math.floor(columns["n_reads_single"][0] * columns["mean_seq_len"][0] / 100) * 100
                assert columns["n_bases_approx"][0] == n_bases_exp
                assert columns["n_read_pairs"][0] == ""
                assert columns["stage"][0] == "test"
            }
            def stage = tsv_basic.columns["stage"][0]
            def sample = tsv_basic.columns["sample"][0]
            // Other TSVs should have expected structure and content
            def tsv_adapt = path(process.out[0][0][2]).csv(sep: "\t", decompress: true)
            with (tsv_adapt) {
                assert columnCount == 6 | columnCount == 0 // No columns if no adaptor contamination

                if (columnCount > 0) {
                    assert columns["stage"][0] == stage
                    assert columns["sample"][0] == sample
                }
            }
            def tsv_qbase = path(process.out[0][0][3]).csv(sep: "\t", decompress: true)
            with (tsv_qbase) {
                assert columnCount == 5
                assert columns["stage"][0] == stage
                assert columns["sample"][0] == sample
            }
            def tsv_qseqs = path(process.out[0][0][4]).csv(sep: "\t", decompress: true)
            with (tsv_qseqs) {
                assert columnCount == 5
                assert columns["stage"][0] == stage
                assert columns["sample"][0] == sample
            }
            def tsv_lengths = path(process.out[0][0][5]).csv(sep: "\t", decompress: true)
            with (tsv_lengths) {
                assert columnCount == 5
                assert columns["stage"][0] == stage
                assert columns["sample"][0] == sample
            }
        }
    }

    test("Should generate appropriate output for uniform read lengths") {
        tag "expect_success"
        tag "interleaved"
        config "tests/configs/run.config"
        setup {
            run("FASTQC_LABELED") {
                script "modules/local/fastqc/main.nf"
                process {
                    '''
                    input[0] = Channel.of("test")
                        | combine(Channel.of("${projectDir}/test-data/toy-data/test-random.fastq"))
                    '''
                }
            }
            run("MULTIQC_LABELED") {
                script "modules/local/multiqc/main.nf"
                process {
                    '''
                    input[0] = "test"
                    input[1] = FASTQC_LABELED.out.zip
                    '''
                }
            }
        }
        when {
            params {
                data_path = "${projectDir}/test-data/toy-data/test-random.fastq"
            }
            process {
                """
                input[0] = MULTIQC_LABELED.out.data
                input[1] = false
                """
            }
        }
        then {
            // Should run without failures
            assert process.success
            // Output should preserve sample ID in tuple
            assert process.out[0][0][0] == "test"
            // Basic stats TSV should match input reads (index 1)
            def fastq_in = path(params.data_path).fastq
            def tsv_basic  = path(process.out[0][0][1]).csv(sep: "\t", decompress: true)
            with (tsv_basic) {
                assert columns["n_reads_single"][0] == fastq_in.readNames.size()
                assert columns["n_read_pairs"][0] == columns["n_reads_single"][0] / 2
                assert columns["mean_seq_len"][0] == fastq_in.sequences[0].length()
                assert columns["n_bases_approx"][0] == columns["n_reads_single"][0] * columns["mean_seq_len"][0]
            }
            // Length stats should match expected output for uniform reads (index 5)
            def tsv_lengths = path(process.out[0][0][5]).csv(sep: "\t", decompress: true)
            def stage = tsv_basic.columns["stage"][0]
            def sample = tsv_basic.columns["sample"][0]
            with (tsv_lengths) {
                assert columnCount == 5
                assert rowCount == 1
                assert columns["stage"][0] == stage
                assert columns["sample"][0] == sample
                assert columns["n_sequences"][0] == fastq_in.readNames.size()
                assert columns["length"][0] == fastq_in.sequences[0].length()
            }
        }
    }

}
