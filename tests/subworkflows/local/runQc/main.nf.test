// Helper function: Validate TSV structure by reading lines directly and splitting by tabs.
// This approach works even when files have only headers (no data rows),
// which can cause issues with nf-test's CSV parser.
def validateTsvStructure = { tsv_file, expected_col_count ->
    def lines = path(tsv_file).linesGzip

    // Verify header exists and has correct number of columns
    assert lines.size() >= 1 : "TSV file must have at least a header row"
    def header = lines[0].split("\t")
    assert header.size() == expected_col_count : "Expected ${expected_col_count} columns, got ${header.size()}"
}

nextflow_workflow {

    name "Test subworkflow RUN_QC"
    script "subworkflows/local/runQc/main.nf"
    workflow "RUN_QC"
    tag "subworkflow"
    tag "run_qc"

    test("Should run without failures on paired (interleaved) data") {
        config "tests/configs/run.config"
        tag "expect_success"
        tag "interleaved"
        when {
            params {}
            workflow {
                """
                input[0] = Channel.of("test")
                    | combine(Channel.of("${projectDir}/test-data/tiny-index/reads/interleaved.fastq"))
                input[1] = Channel.of("test")
                    | combine(Channel.of("${projectDir}/test-data/tiny-index/reads/interleaved.fastq"))
                input[2] = Channel.of(false)
                """
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Basic stats TSV should have expected structure and content
            def tsv_basic = path(workflow.out.qc_basic[0]).csv(sep: "\t", decompress: true)
            assert tsv_basic.rowCount == 2
            assert tsv_basic.columnCount == 18
            // Other TSVs should have expected structure and content
            validateTsvStructure(workflow.out.qc_adapt[0], 6)
            validateTsvStructure(workflow.out.qc_qbase[0], 5)
            validateTsvStructure(workflow.out.qc_qseqs[0], 5)
            validateTsvStructure(workflow.out.qc_lengths[0], 5)
        }
    }

    test("Should run without failures on single-end data") {
        config "tests/configs/run.config"
        tag "expect_success"
        tag "single_end"
        when {
            params {}
            workflow {
                """
                input[0] = Channel.of("test")
                    | combine(Channel.of("${projectDir}/test-data/tiny-index/reads/R1.fastq"))
                input[1] = Channel.of("test")
                    | combine(Channel.of("${projectDir}/test-data/tiny-index/reads/R1.fastq"))
                input[2] = Channel.of(true)
                """
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Basic stats TSV should have expected structure and content
            def tsv_basic = path(workflow.out.qc_basic[0]).csv(sep: "\t", decompress: true)
            assert tsv_basic.rowCount == 2
            assert tsv_basic.columnCount == 18
            // Other TSVs should have expected structure and content
            validateTsvStructure(workflow.out.qc_adapt[0], 6)
            validateTsvStructure(workflow.out.qc_qbase[0], 5)
            validateTsvStructure(workflow.out.qc_qseqs[0], 5)
            validateTsvStructure(workflow.out.qc_lengths[0], 5)
        }
    }
    
    test("Should handle empty input files properly") {
        config "tests/configs/run.config"
        tag "expect_success"
        tag "empty_input"
        when {
            params {}
            workflow {
                """
                input[0] = Channel.of("test")
                    | combine(Channel.of("${projectDir}/test-data/toy-data/empty_file.txt"))
                input[1] = Channel.of("test")
                    | combine(Channel.of("${projectDir}/test-data/toy-data/empty_file.txt"))
                input[2] = Channel.of(true)
                """
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Basic stats TSV should have expected structure and content
            def tsv_basic = path(workflow.out.qc_basic[0]).csv(sep: "\t", decompress: true)
            assert tsv_basic.rowCount == 2
            assert tsv_basic.columnCount == 18
            // Lengths TSV should have expected structure and content
            def tsv_lengths = path(workflow.out.qc_lengths[0]).csv(sep: "\t", decompress: true)
            assert tsv_lengths.rowCount == 2
            assert tsv_lengths.columnCount == 5
            // Other TSVs should have expected structure and content
            validateTsvStructure(workflow.out.qc_adapt[0], 6)
            validateTsvStructure(workflow.out.qc_qbase[0], 5)
            validateTsvStructure(workflow.out.qc_qseqs[0], 5)
        }
    }
}
