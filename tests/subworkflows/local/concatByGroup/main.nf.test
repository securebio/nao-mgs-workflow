nextflow_workflow {

    name "Test workflow CONCAT_BY_GROUP"
    script "subworkflows/local/concatByGroup/main.nf"
    workflow "CONCAT_BY_GROUP"
    config "tests/configs/run.config"
    tag "subworkflow"
    tag "downstream"
    tag "concat_by_group"

    test("Should run without failures") {
        tag "expect_success"
        when {
            params {
            }
            workflow {
                '''
                // Input: tuple(label, sample, file, group)
                input[0] = Channel.of(
                    ["tt1", "tiny_test", file("${projectDir}/test-data/prepareGroupTsvs/tt1_hits.tsv"), "group_a"],
                    ["tt2", "tiny_test_2", file("${projectDir}/test-data/prepareGroupTsvs/tt2_hits.tsv"), "group_b"]
                )
                input[1] = "hits.tsv"
                input[2] = "test_output"
                '''
            }
        }
        then {
            assert workflow.success

            // Count input rows for verification
            def input_tsv = path("${projectDir}/test-data/prepareGroupTsvs/tt1_hits.tsv").csv(sep: "\t")
            def input_row_count = input_tsv.rowCount
            def input_col_count = input_tsv.columnCount

            // Should produce one output per unique group
            assert workflow.out.groups.size() == 2

            // Each output should be a tuple of (group, file)
            def output_groups = workflow.out.groups.collect { it[0] } as Set
            assert output_groups == ["group_a", "group_b"] as Set

            // Verify output file naming matches expected pattern
            workflow.out.groups.each { output ->
                def group = output[0]
                def filename = path(output[1]).getFileName().toString()
                assert filename == "${group}_test_output.tsv.gz"
            }

            // Verify output structure and content for each group
            workflow.out.groups.each { output ->
                def group = output[0]
                def tsv = path(output[1]).csv(sep: "\t", decompress: true)

                // Should have original columns plus "group" column
                assert tsv.columnCount == input_col_count + 1
                assert "group" in tsv.columnNames

                // All rows should have the correct group value
                tsv.columns["group"].each { val ->
                    assert val == group
                }
            }

            // Verify row counts are preserved after concatenation
            def group_a_output = workflow.out.groups.find { it[0] == "group_a" }
            def group_b_output = workflow.out.groups.find { it[0] == "group_b" }
            def group_a_tsv = path(group_a_output[1]).csv(sep: "\t", decompress: true)
            def group_b_tsv = path(group_b_output[1]).csv(sep: "\t", decompress: true)

            // Each group has 1 input file
            assert group_a_tsv.rowCount == input_row_count
            assert group_b_tsv.rowCount == input_row_count

            // Total row count should equal sum of input rows
            def total_output_rows = group_a_tsv.rowCount + group_b_tsv.rowCount
            assert total_output_rows == 2 * input_row_count
        }
    }
}
