nextflow_workflow {

    name "Test subworkflow EXTRACT_VIRAL_READS_SHORT"
    script "subworkflows/local/extractViralReadsShort/main.nf"
    workflow "EXTRACT_VIRAL_READS_SHORT"
    config "tests/configs/run.config"
    tag "subworkflow"
    tag "extract_viral_reads_short"

    test("Should run without failures") {
        tag "expect_success"
        tag "paired_end"
        when {
            params {
                bt2_score_threshold = 20
            }
            workflow {
                '''
                def short_params = [
                    aln_score_threshold: params.bt2_score_threshold,
                    adapters: params.adapters,
                    min_kmer_hits: "1",
                    k: "24",
                    bbduk_suffix: "viral",
                    taxid_artificial: "81077",
                    db_download_timeout: params.db_download_timeout
                ]
                input[0] = Channel.of(["test", ["${projectDir}/test-data/tiny-index/reads/R1.fastq", "${projectDir}/test-data/tiny-index/reads/R2.fastq"]])
                input[1] = params.ref_dir
                input[2] = short_params
                '''
            }
        }
        then {
            assert workflow.success
            // Output should be valid FASTQ with an even number of entries (interleaved)
            def test_reads_fastq = path(workflow.out.test_reads[0][1]).fastq
            def test_reads_count = test_reads_fastq.getNumberOfRecords()
            assert test_reads_count > 0
            assert test_reads_count % 2 == 0
            // LCA'd output rows should be less than or equal to pre lca rows
            def pre_lca_files = workflow.out.hits_prelca.collect { it[1] }
            def total_pre_lca_rows = pre_lca_files.sum { file ->
                  path(file).linesGzip.size() - 1  // minus header for each file
            }
            def hits_final_tab = path(workflow.out.hits_final[0][1]).csv(sep: "\t", decompress: true)
            assert hits_final_tab.rowCount <= total_pre_lca_rows
        }
    }
    
    test("Should handle empty input file") {
        tag "empty_file"
        tag "expect_success"
        when {
            params {
                bt2_score_threshold = 20
            }
            workflow {
                '''
                def short_params = [
                    aln_score_threshold: params.bt2_score_threshold,
                    adapters: params.adapters,
                    min_kmer_hits: "1",
                    k: "24",
                    bbduk_suffix: "viral",
                    taxid_artificial: "81077",
                    db_download_timeout: params.db_download_timeout
                ]
                input[0] = Channel.of(["test", ["${projectDir}/test-data/toy-data/empty_file.txt", "${projectDir}/test-data/toy-data/empty_file_2.txt"]])
                input[1] = params.ref_dir
                input[2] = short_params
                '''
            }
        }
        then {
            assert workflow.success
            // FASTQ output files should be empty
            def fastq_files = [
                path(workflow.out.bbduk_match[0][1]),
                path(workflow.out.bbduk_trimmed[0][1]),
                path(workflow.out.test_reads[0][1])
            ]
            def fastqs = fastq_files.collect{ it.fastq }
            def read_counts = fastqs.collect{ it.getNumberOfRecords() }
            assert read_counts.every{ it == 0 }
            // Tabular output files should have only header lines
            def tabular_files = [
                path(workflow.out.hits_final[0][1]),
                path(workflow.out.hits_prelca[0][1])
            ]
            def tabular_lines = tabular_files.collect{ it.linesGzip.toList() }
            assert tabular_lines.every{ it.size() == 1 }
        }
    }
}
