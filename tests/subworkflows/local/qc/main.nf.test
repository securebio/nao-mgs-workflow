// Helper function: Validate TSV structure by reading lines directly and splitting by tabs.
// This approach works even when files have only headers (no data rows),
// which can cause issues with nf-test's CSV parser.
def validateTsvStructure = { tsv_file, expected_col_count, expected_stage, expected_sample ->
    def lines = path(tsv_file).linesGzip

    // Verify header exists and has correct number of columns
    assert lines.size() >= 1 : "TSV file must have at least a header row"
    def header = lines[0].split("\t")
    assert header.size() == expected_col_count : "Expected ${expected_col_count} columns, got ${header.size()}"

    // If there are data rows, verify stage and sample columns
    if (lines.size() > 1) {
        def first_data_row = lines[1].split("\t", -1) // -1 keeps trailing empty strings
        def stage_idx = header.findIndexOf { it == "stage" }
        def sample_idx = header.findIndexOf { it == "sample" }

        assert stage_idx >= 0 : "Header must contain 'stage' column"
        assert sample_idx >= 0 : "Header must contain 'sample' column"
        assert first_data_row[stage_idx] == expected_stage : "Expected stage '${expected_stage}', got '${first_data_row[stage_idx]}'"
        assert first_data_row[sample_idx] == expected_sample : "Expected sample '${expected_sample}', got '${first_data_row[sample_idx]}'"
    }
}

nextflow_workflow {

    name "Test subworkflow QC"
    script "subworkflows/local/qc/main.nf"
    workflow "QC"
    tag "subworkflow"
    tag "qc"

    test("Should run without failures on paired data") {
        config "tests/configs/run.config"
        tag "expect_success"
        tag "interleaved"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                workflow {
                    '''
                    input[0] = "${projectDir}/test-data/samplesheet.csv"
                    input[1] = "illumina"
                    input[2] = false
                    '''
                }
            }
            run("INTERLEAVE_FASTQ") {
                script "modules/local/interleaveFastq/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    '''
                }
            }
        }
        when {
            params {}
            workflow {
                """
                input[0] = INTERLEAVE_FASTQ.out.output
                input[1] = "test"
                input[2] = LOAD_SAMPLESHEET.out.single_end
                """
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Basic stats TSV should have expected structure and content
            def tsv_basic = path(workflow.out.qc[0][0]).csv(sep: "\t", decompress: true)
            def fastq_in = path(workflow.out.test_input[0][1]).fastq
            def seqs_in = fastq_in.sequences
            def n_bases = seqs_in.collect{ it.length() }.sum()
            with (tsv_basic) {
                assert rowCount == 1
                assert columnCount == 18
                assert columns["n_reads_single"][0] == seqs_in.size()
                assert columns["n_reads_single"][0] == columns["n_read_pairs"][0] * 2
                assert Math.abs(columns["mean_seq_len"][0] - (n_bases / seqs_in.size())) < 0.001
                def n_bases_exp = Math.floor(columns["n_reads_single"][0] * columns["mean_seq_len"][0] / 100) * 100
                assert columns["n_bases_approx"][0] == n_bases_exp
                assert columns["stage"][0] == "test"
            }
            def stage = tsv_basic.columns["stage"][0]
            def sample = tsv_basic.columns["sample"][0]
            // Other TSVs should have expected structure and content
            def tsv_adapt = workflow.out.qc[0][1]
            validateTsvStructure(tsv_adapt, 6, stage, sample)
            def tsv_qbase = workflow.out.qc[0][2]
            validateTsvStructure(tsv_qbase, 5, stage, sample)
            def tsv_qseqs = workflow.out.qc[0][3]
            validateTsvStructure(tsv_qseqs, 5, stage, sample)
            def tsv_lengths = workflow.out.qc[0][4]
            validateTsvStructure(tsv_lengths, 5, stage, sample)
        }
    }

    test("Should run without failures on single-end data") {
        config "tests/configs/run.config"
        tag "expect_success"
        tag "single_end"
        setup {
            run("LOAD_SAMPLESHEET") {
                script "subworkflows/local/loadSampleSheet/main.nf"
                workflow {
                    '''
                    input[0] = "${projectDir}/test-data/single-end-samplesheet.csv"
                    input[1] = "illumina"
                    input[2] = true
                    '''
                }
            }
            run("COPY_FILE") {
                script "modules/local/copyFile/main.nf"
                process {
                    '''
                    input[0] = LOAD_SAMPLESHEET.out.samplesheet
                    input[1] = "reads.fastq.gz"
                    '''
                }
            }
        }
        when {
            params {}
            workflow {
                """
                input[0] = COPY_FILE.out
                input[1] = "test"
                input[2] = LOAD_SAMPLESHEET.out.single_end
                """
            }
        }
        then {
            // Should run without failures
            assert workflow.success
            // Basic stats TSV should have expected structure and content
            def tsv_basic  = path(workflow.out.qc[0][0]).csv(sep: "\t", decompress: true)
            def fastq_in = path(workflow.out.test_input[0][1]).fastq
            def seqs_in = fastq_in.sequences
            def n_bases = seqs_in.collect{ it.length() }.sum()
            with (tsv_basic) {
                assert rowCount == 1
                assert columnCount == 18
                assert columns["n_reads_single"][0] == seqs_in.size()
                assert Math.abs(columns["mean_seq_len"][0] - (n_bases / seqs_in.size())) < 0.001
                def n_bases_exp = Math.floor(columns["n_reads_single"][0] * columns["mean_seq_len"][0] / 100) * 100
                assert columns["n_bases_approx"][0] == n_bases_exp
                assert columns["n_read_pairs"][0] == ""
                assert columns["stage"][0] == "test"
            }
            def stage = tsv_basic.columns["stage"][0]
            def sample = tsv_basic.columns["sample"][0]
            // Other TSVs should have expected structure and content
            def tsv_adapt = workflow.out.qc[0][1]
            validateTsvStructure(tsv_adapt, 6, stage, sample)
            def tsv_qbase = workflow.out.qc[0][2]
            validateTsvStructure(tsv_qbase, 5, stage, sample)
            def tsv_qseqs = workflow.out.qc[0][3]
            validateTsvStructure(tsv_qseqs, 5, stage, sample)
            def tsv_lengths = workflow.out.qc[0][4]
            validateTsvStructure(tsv_lengths, 5, stage, sample)
        }
    }

}
